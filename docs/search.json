[
  {
    "objectID": "homework/01-homework.html",
    "href": "homework/01-homework.html",
    "title": "Homework 01",
    "section": "",
    "text": "Suppose the globe tossing data (Lecture 2, Chapter 2) had turned out to be 4 water and 11 land. Construct the posterior distribution.\n\n\nsource('R/packages.R')\n\n\nAttaching package: 'ggdag'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nsource('R/compute_posterior_globe.R')\n\n\nn_water <- 4\nn_land <- 11\nx <- c(rep('W', n_water), rep('L', n_land))\nn_possibilities <- 5\nposterior <- compute_posterior_globe(x, n_possibilities = n_possibilities)\n\nkable(posterior, digits = 4)\n\n\n\n\nW\nL\npossibility\nways\npost\n\n\n\n\n4\n11\n0.00\n0\n0.0000\n\n\n4\n11\n0.25\n177147\n0.8436\n\n\n4\n11\n0.50\n32768\n0.1560\n\n\n4\n11\n0.75\n81\n0.0004\n\n\n4\n11\n1.00\n0\n0.0000\n\n\n\n\n# Using a finer grid with more potential possibilities\nn_possibilities <- 100\nposterior <- compute_posterior_globe(x, n_possibilities = n_possibilities)"
  },
  {
    "objectID": "homework/01-homework.html#question-2",
    "href": "homework/01-homework.html#question-2",
    "title": "Homework 01",
    "section": "Question 2",
    "text": "Question 2\n\nUsing the posterior distribution from 1, compute the posterior predictive distribution for the next 5 tosses of the same globe. I recommend you use the sampling method.\n\n\npossibilities <- seq(0, 1, length.out = n_possibilities)\nsize <- 1e4\nn_tosses <- 5\n\n\n# == Sampling approach from posterior\n# Sample with probability posterior distribution calculated in Question 1\n# using the grid of possibilities (sequence of numbers between 0 and 1)\nposterior_samples <- sample(\n    possibilities,\n    size = size,\n    prob = posterior$post,\n    replace = TRUE\n)\n\n# Using the posterior predicted proportion of water, simulate 5 tosses for each\nposterior_predict <- rbinom(size, size = n_tosses, p = posterior_samples)\n\n# Plot number of W tosses \nplot(table(posterior_predict), xlab = 'number of W tosses', ylab = '', \n         main = 'Posterior predicted')\n\n\n\n# === Sampling approach from representative Beta distribution\nbeta_samples <- rbeta(\n    size,\n    n_water + 1,\n    n_land + 1\n)\n\n# Using the beta distribution predicted proportion of water, simulate 5 tosses for each\nbeta_predict <- rbinom(size, size = n_tosses, p = beta_samples)\n\n# Plot number of W tosses \nplot(table(beta_predict), xlab = 'number of W tosses', ylab = '', \n         main = 'Beta distribution predicted')"
  },
  {
    "objectID": "homework/01-homework.html#question-3",
    "href": "homework/01-homework.html#question-3",
    "title": "Homework 01",
    "section": "Question 3",
    "text": "Question 3\n\nUse the posterior predictive distribution from 2 to calculate the probability of 3 or more water samples in the next 5 tosses.\n\n\n# Predicted probability of 3 or more water samples in the next 5 tosses\n#  given posterior predictive distribution\ntable(posterior_predict >= 3) / size\n\n\n FALSE   TRUE \n0.8192 0.1808 \n\n# and beta distribution prediction\ntable(beta_predict >= 3) / size\n\n\n FALSE   TRUE \n0.8246 0.1754"
  },
  {
    "objectID": "homework/01-homework.html#question-4-optional",
    "href": "homework/01-homework.html#question-4-optional",
    "title": "Homework 01",
    "section": "Question 4 (optional)",
    "text": "Question 4 (optional)\n\nThis problem is an optional challenge for people who are taking the course for a second or third time. Suppose you observe W = 5 water points, but you forgot to write down how many times the globe was tossed, so you don’t know the number of land points L. Assume that p = 0.7 and compute the posterior distribution of the number of tosses N. Hint: Use the binomial distribution.\n\n\np <- 0.7\nn_water <- 5\n\nn_samples <- seq(5, 15)\n\nd <- vapply(n_samples, dbinom, x = n_water, prob = p, FUN.VALUE = 42)\n\nkable(data.table(\n    n_samples = n_samples,\n    post = d\n))\n\n\n\n\nn_samples\npost\n\n\n\n\n5\n0.1680700\n\n\n6\n0.3025260\n\n\n7\n0.3176523\n\n\n8\n0.2541218\n\n\n9\n0.1715322\n\n\n10\n0.1029193\n\n\n11\n0.0566056\n\n\n12\n0.0291115\n\n\n13\n0.0141918\n\n\n14\n0.0066229\n\n\n15\n0.0029803"
  },
  {
    "objectID": "homework/00-homework-listing.html",
    "href": "homework/00-homework-listing.html",
    "title": "Homework",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nDate\n\n\nAuthor\n\n\n\n\n\n\nHomework 01\n\n\nFeb 1, 2023\n\n\nAlec L. Robitaille\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/01-notes.html",
    "href": "notes/01-notes.html",
    "title": "Lecture 01 Notes",
    "section": "",
    "text": "Statistical models process data but to provide insight, we require scientific models. Causes of data cannot be extracted alone using a statistical model, we need causal models.\nCausal inference is the prediction of intervention and imputation of missing observations.\nCausal prediction: knowing a cause means being able to predict the consequences of an intervention. Causal imputation: knowing a cause means being able to construct unobserved counterfactual outcomes.\n\n\n\n\n\n\nX is a treatment\nY is an outcome\nB is a competing cause of Y\nA is an influence of the treatment X\nC is a common cause of X and Y (a confound)\n\nRelationships between all variables can impact outcomes.\n\n\n\n\n\n\nNote\n\n\n\nAt one moment in time, DAGs are unidirectional. With a time series, you can have reciprocal relationships.\n\n\nDAGs are not specific to one model and therefore can be used for different queries and related models. These different models should not necessarily include all variables, and DAGs help us determine good and bad controls for each question. DAGs are logically specific and can be used to test and refine the causal model.\n\n\n\n\n\n\nNote\n\n\n\nHow do we justify controls in eg. the relationship between X and Y?\n\nWe need a DAG\nthen we analyse it to determine the adjustment set"
  },
  {
    "objectID": "notes/01-notes.html#golems",
    "href": "notes/01-notes.html#golems",
    "title": "Lecture 01 Notes",
    "section": "Golems",
    "text": "Golems\nStatistical models are powerful but dangerous and have no wisdom or foresight. Flowcharts of tests that are isolated for specific uses are not intuitive or appropriate for research science. Null hypothesis rejection is not appropriate, feasible or ethical in many contexts.\n\n\n\n\n\n\nReflect\n\n\n\nWhat are other process models that are consistent with this same fact?"
  },
  {
    "objectID": "notes/01-notes.html#owls",
    "href": "notes/01-notes.html#owls",
    "title": "Lecture 01 Notes",
    "section": "Owls",
    "text": "Owls\nEmphasis on documenting and testing code, using a respectable workflow\n\nTheoretical estimand\nScientific (causal) model\nUse the theoretical estimand and the scientific model to build a statistical model\nSimulate from the scientific model to validate that the statistical model yields the theoretical estimand\nAnalyse the real data"
  },
  {
    "objectID": "notes/02-notes.html",
    "href": "notes/02-notes.html",
    "title": "Lecture 02 Notes",
    "section": "",
    "text": "Bayesian data analysis is Bayesian inference applied to scientific data analysis. For each possible explanation of the sample, count all the ways the sample could have happened and explanations with more ways to produce the sample are more plausible.\nNo guarantees except logical. Probability theory is a method of logically deducing the implications of data under the assumptions that you must choose."
  },
  {
    "objectID": "notes/02-notes.html#workflow",
    "href": "notes/02-notes.html#workflow",
    "title": "Lecture 02 Notes",
    "section": "Workflow",
    "text": "Workflow\n\nDefine generative model of the sample\nDefine a specific estimand\nDesign a statistical way to produce estimand\nTest the statistical method using the generative model\nAnalyse the sample, summarize"
  },
  {
    "objectID": "notes/02-notes.html#globe-tossing-model",
    "href": "notes/02-notes.html#globe-tossing-model",
    "title": "Lecture 02 Notes",
    "section": "Globe tossing model",
    "text": "Globe tossing model\nEstimand: proportion of globe covered in water\nGiven N samples, how should we use the sample? Produce a summary of the sample? Represent uncertainty?\nFirst, think about how sample is produced and how variables influence on another.\n\np = proportion of water\nW = land observations\nW = water observations\nN = number of tosses\n\n\n\n\n\n\n\nNote\n\n\n\nVariables can be things you observed or things you want to estimate\n\n\n\n\n\n\n\nN influences W and L: if you were to intervene on N (eg. increase the number of observations), it would change W and L.\nTo make the DAG generative, we need to define these relationships as a function.\n\\(W, L = f (P, N)\\)\nWhat is the function?\n\n\n\n\nW L W\nW\n\n\n\n\n\n4 L\n0 x 4 x 0\n0 x 0\n0\n\n\n3 L 1 W\n1 x 3 x 1\n3 x 1\n3\n\n\n2 L 2 W\n2 x 2 x 2\n8 x 2\n16\n\n\n1 L 3 W\n3 x 1 x 3\n9 x 3\n27\n\n\n4 W\n4 x 0 x 4\n0 x 4\n0\n\n\n\nGiven the table and our scientific understanding, the function is:\n\\(W, L = (4p) ^ {W} * (4-4p) ^ {L}\\)"
  },
  {
    "objectID": "notes/02-notes.html#generative-simulation",
    "href": "notes/02-notes.html#generative-simulation",
    "title": "Lecture 02 Notes",
    "section": "Generative simulation",
    "text": "Generative simulation\nSimulate a data set with known parameters, then test if your statistical estimator returns these known parameters.\nRepeat with different sampling designs, with extreme simulations (eg. all W or all L)."
  },
  {
    "objectID": "notes/02-notes.html#bayesian-inference",
    "href": "notes/02-notes.html#bayesian-inference",
    "title": "Lecture 02 Notes",
    "section": "Bayesian inference",
    "text": "Bayesian inference\n\nNo minimum sample size\nThe shape of the posterior distribution embodies the sample size\nNo point estimate. The distribution is the estimate, always use the entire distribution.\nNo one true interval. Nothing happens at the boundary."
  },
  {
    "objectID": "notes/02-notes.html#posterior-predictive-simulations",
    "href": "notes/02-notes.html#posterior-predictive-simulations",
    "title": "Lecture 02 Notes",
    "section": "Posterior predictive simulations",
    "text": "Posterior predictive simulations\nUse samples from the entire posterior distribution to determine implications of the model.\nUncertainty -> causal model -> implications\nTypes:\n\nmodel-based forecasts\ncausal effects\ncounterfactuals\nprior predictions"
  },
  {
    "objectID": "notes/02-notes.html#misclassification",
    "href": "notes/02-notes.html#misclassification",
    "title": "Lecture 02 Notes",
    "section": "Misclassification",
    "text": "Misclassification\nConsider the true number of water samples is unobserved, eg. due to measurement error. W* (W_star) is misclassified sample, influenced by the measurement process (M).\nNote: this DAG is simplified to remove L since N - L = W\n\n\n\n\n\nNext, use a simulation to determine the potential impact of misclassification.\nDefine a function with a new variable X, the misclassification rate, that takes a simulated sample then introduces error. The misclassification estimator returns a new formula for the posterior distribution.\nIf there is measurement error, better to model it than to ignore it. Samples do not need to be representative of the population in order to provide good estimates of the population. The priority is to determine in which ways (why) the sample differs from the population. Then you can modeol the sample process and the causal differences for the population."
  },
  {
    "objectID": "notes/00-notes-listing.html",
    "href": "notes/00-notes-listing.html",
    "title": "Notes",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nDate\n\n\nAuthor\n\n\n\n\n\n\nLecture 01 Notes\n\n\nJan 9, 2023\n\n\nAlec L. Robitaille\n\n\n\n\nLecture 02 Notes\n\n\nJan 9, 2023\n\n\nAlec L. Robitaille\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Statistical Rethinking colearning 2023",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\n\n\n\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting\n\n\n\n\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\n\n\n\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to Alec (robit.alec@gmail.com), or Bella (isabella.richmond@mail.concordia.ca). If any concerns are related to Alec or Bella, please contact Eric Vander Wal (eric.vanderwal@mun.ca). All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident.\n\n\n\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Statistical Rethinking colearning 2023",
    "section": "Attribution",
    "text": "Attribution\nThis Code of Conduct is adapted from the Contributor Covenant homepage, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at ttps://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Rethinking colearning 2023",
    "section": "",
    "text": "Second round of Statistical Rethinking colearning, this time with 2023 lectures and homework.\nThe first round of Statistical Rethinking colearning (2022) is available here.\n\n\n\n\n\n\n\nMeeting date\nReading\nLectures\n\n\n\n\n26 January\nChapters 1, 2 and 3\n[1] <Science Before Statistics> <Slides>  [2] <Garden of Forking Data> <Slides>\n\n\n09 February\nChapter 4\n[3] <Geocentric Models> <Slides>  [4] <Categories and Curves> <Slides>\n\n\n\n\n\n\n\n\n\nMeeting date\nHomework\nSolutions\n\n\n\n\n2 February\nHomework 1\nSolutions\n\n\n\n\n\n\n\n\nAlec (this repo)\nBella\nChristina\nJack\n\n\n\n\nAdditional material using other packages or languages\n\nOriginal R: https://github.com/rmcelreath/rethinking/\nR + Tidyverse + ggplot2 + brms: https://bookdown.org/content/4857/\nPython and PyMC3: Python/PyMC3\nJulia and Turing: https://github.com/StatisticalRethinkingJulia and https://github.com/StatisticalRethinkingJulia/TuringModels.jl\n\nSee Richard’s comments about these here: https://github.com/rmcelreath/stat_rethinking_2023#coding\n2022 colearning:\n\nLectures: https://github.com/rmcelreath/stat_rethinking_2022#calendar–topical-outline\nHomework: https://github.com/rmcelreath/stat_rethinking_2022/tree/main/homework\n\nAlso, Alec’s notes and solutions of the 2019 material: https://github.com/robitalec/statistical-rethinking and https://www.statistical-rethinking.robitalec.ca/\n\n\n\nPackage specific install directions. We’ll update these as we go!\nRethinking\n\nrethinking\n\nStan\n\ncmdstanr\nRStan\nbrms\n\nTargets\n\ntargets\nstantargets\n\nV8, needed for the dagitty package\n\nV8\n\n\n\n\nPlease note that this project is released with a Code of Conduct. By participating in this project you agree to abide by its terms."
  },
  {
    "objectID": "notes/03-notes.html",
    "href": "notes/03-notes.html",
    "title": "Lecture 03 Notes",
    "section": "",
    "text": "Prediction without explanation. The geocentric model has epicycles and Earth is the center of the universe.\nLinear regressions are geocentric - they describe associations, make predictions bubt are mechanically wrong. Therefore, they are useful when handled with care.\n\n\nSummed fluctuations tend towards the normal distribution\nFor estimating only the mean and variance, the normal distribution is the least informative distribution (maxent).\nNote: variables do not have to be normally distributed for normal models to be useful."
  },
  {
    "objectID": "notes/03-notes.html#linear-regression",
    "href": "notes/03-notes.html#linear-regression",
    "title": "Lecture 03 Notes",
    "section": "Linear regression",
    "text": "Linear regression\n\nWorkflow\n\nQuestion/goal/estimand\nScientific model\nStatistical model(s)\nValidate model\nAnalyze data\n\n\n\nExample: Howell data\n\n1. Estimand\nDescribe the association between adult weight and height\n\n\n2. Scientific model\nHow does height influence weight?\nH -> W <- U\n\\(W = f(H, U)\\)\n“Weight is some function of height and unobserved variables”\n\nVariables: W, U, H\nDefinitions:\n\n\\(W = \\beta H + U\\) (Equation for expected weight)\n\\(U_{i} \\sim Normal(0, \\sigma)\\) (Gaussian error with standard deviation sigma)\n\\(H_{i} \\sim Uniform(130, 170)\\) (Height is uniformly distributed from 130-170 cm)\n\n\\(_{i}\\) represents individuals.\nThere is a deterministic relationship for W and distributional relationships for U and H.\n\n\n\n3. Statistical model\n\\(E(W_{i} | H_{i}) = \\alpha + \\beta H_{i}\\)\n\n\\(E(W_{i} | H_{i})\\): average weight conditional on height\n\\(\\alpha\\): intercept\n\\(\\beta H_{i}\\): slope\n\n\nPosterior distribution\n\\(Pr(\\alpha, \\beta, \\sigma | H_{i}, W_{i}) = \\frac{Pr(W_{i} | H_{i}, \\alpha, \\beta, \\sigma) Pr (\\alpha, \\beta, \\sigma)}{Z}\\)\n\n\\(Pr(\\alpha, \\beta, \\sigma | H_{i}, W_{i})\\): posterior probability of a specific line\n\\(Pr(W_{i} | H_{i}, \\alpha, \\beta, \\sigma)\\): garden of forking data, the number of ways we could see the observations, conditional on an exact line (in this case)\n\\(Pr (\\alpha, \\beta, \\sigma)\\): prior\n\\(Z\\): normalizing constant\n\nAlpha, beta and sigma are unobserved variables, height and weight are observed.\nThe posterior distribution is proportional to the product of the number of ways the observations could arise according to our assumptions multiplied by our prior.\n\n\nPrior predictive simulation\nWhat do the observable variables look like with these priors?\n\\(W_{i} \\sim Normal(\\mu_{i}, \\sigma)\\)\n\\(\\mu_{i} = \\alpha + \\beta H_{i}\\)\n\\(\\alpha ~ Normal(0, 10)\\)\n\\(\\beta ~ Uniform(0, 1)\\)\n\\(\\sigma ~ Uniform(0, 10)\\)\nWhen height is 0, weight is 0. Weight increases on average with height. Weight (kg) is less than height (cm). Sigma must be positive.\nPriors:\n\nno correct priors, only scientifically justifiable priors.\njustify with information outside the data, like the rest of the model\npriors become more important as models get more complex\nalways simulate from the priors, better than trying to intuit what they mean from the definitions\n\n\n\n\n4. Validate model\nTest statistical model with simulated observations from scientific model. Stronger test: simulation-based calibration\n\nsimulate individuals with known parameters from scientific model\nuse model to determine if it can recover parameters\nuse a large sample\ntest with different values and sample sizes\n\n\n\n5. Analyze the data\nOnce you’ve done steps 1-4, you can just drop in the real data.\nParameters are not independent, do not interpret them separately.\nUse the posterior distribution to generate predictions then describe and interpret those."
  }
]